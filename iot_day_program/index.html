<!doctype html><html lang=en-us><head><title>ACM MobiSys 2025 - IoT Day Program</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=title content="ACM MobiSys 2025 - IoT Day Program"><meta name=keywords content="MobiSys25,MobiSys2025,MobiSys'2025,MobiSys'25"><meta http-equiv=Cache-Control content="no-store, no-cache, must-revalidate"><meta http-equiv=Pragma content="no-cache"><meta http-equiv=Expires content="0"><link rel=icon href=https://www.sigmobile.org/mobisys/2025/favicon.ico><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.13.1/font/bootstrap-icons.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href='/mobisys/2025/css/icomoon/style.css?v=5836e593'><link rel=stylesheet href=/mobisys/2025/css/main.min.e46cae4ab23fe01e1f261a8e8719d2127932ddb31948da18c3fbab05dec27b4f.css integrity="sha256-5GyuSrI/4B4fJhqOhxnSEnky3bMZSNoYw/urBd7Ce08=" crossorigin=anonymous></head><body><nav><div class=container><input type=checkbox id=hamburger>
<label for=hamburger></label><p class=navbar-title>ACM MobiSys 2025</p><ul class=navbar-nav><li class=nav-item><a href=/mobisys/2025/>Home</a></li><li class=nav-item><a href=#>Calls
<span></span></a><ul class=dropdown-menu><li class=dropdown-item><a href=/mobisys/2025/call_for_papers/>Call For Papers</a></li><li class=dropdown-item><a href=/mobisys/2025/call_for_posters/>Call For Posters</a></li><li class=dropdown-item><a href=/mobisys/2025/call_for_workshops/>Call For Workshops</a></li><li class=dropdown-item><a href=/mobisys/2025/call_for_demos/>Call For Demos</a></li><li class=dropdown-item><a href=/mobisys/2025/artifact_evaluation/>Artifact Evaluation</a></li><li class=dropdown-item><a href=/mobisys/2025/n2women/>N<sup>2</sup>Women</a></li><li class=dropdown-item><a href=/mobisys/2025/rising_stars/>Rising Stars Forum</a></li></ul></li><li class=nav-item><a href=#>Accepted
<span></span></a><ul class=dropdown-menu><li class=dropdown-item><a href=/mobisys/2025/accepted_papers/>Accepted Papers</a></li><li class=dropdown-item><a href=/mobisys/2025/accepted_posters/>Accepted Posters</a></li><li class=dropdown-item><a href=/mobisys/2025/accepted_demos/>Accepted Demos</a></li><li class=dropdown-item><a href=/mobisys/2025/accepted_workshops/>Accepted Workshops</a></li></ul></li><li class=nav-item><a href=#>Program
<span></span></a><ul class=dropdown-menu><li class=dropdown-item><a href=/mobisys/2025/program/>Full Program</a></li><li class=dropdown-item><a href=/mobisys/2025/keynotes/>Keynotes</a></li><li class=dropdown-item><a href=/mobisys/2025/iot_day_program/>IoT Day Program</a></li><li class=dropdown-item><a href=/mobisys/2025/n2women_program/>N<sup>2</sup>Women Program</a></li><li class=dropdown-item><a href=/mobisys/2025/rising_stars_program/>Rising Stars Forum Program</a></li></ul></li><li class=nav-item><a href=#>Attending
<span></span></a><ul class=dropdown-menu><li class=dropdown-item><a href=/mobisys/2025/code_of_conduct/>Code of Conduct</a></li><li class=dropdown-item><a href=/mobisys/2025/registration/>Registration</a></li><li class=dropdown-item><a href=/mobisys/2025/visa/>Visa Information</a></li><li class=dropdown-item><a href=/mobisys/2025/venue/>Venue</a></li><li class=dropdown-item><a href=/mobisys/2025/transportation/>Transportation</a></li><li class=dropdown-item><a href=/mobisys/2025/sightseeing/>Sightseeing</a></li><li class=dropdown-item><a href=/mobisys/2025/student_travel_grant/>Student Travel Grant</a></li><li class=dropdown-item><a href=/mobisys/2025/student_volunteering/>Student Volunteering</a></li></ul></li><li class=nav-item><a href=#>Committees
<span></span></a><ul class=dropdown-menu><li class=dropdown-item><a href=/mobisys/2025/organizing_committee/>Organizing Committee</a></li><li class=dropdown-item><a href=/mobisys/2025/program_committee/>Program Committee</a></li><li class=dropdown-item><a href=/mobisys/2025/artifact_evaluation_committee/>Artifact Evaluation Committee</a></li><li class=dropdown-item><a href=/mobisys/2025/pc_self_nomination/>PC Self Nomination</a></li></ul></li><li class=nav-item><a href=/mobisys/2025/sponsorship/>Sponsorship</a></li></ul></div></nav><header class=subpage-background><div class=container><div class=banner><h1 class=title><span class=acm>ACM</span>
<span class=icon-mobisys2025></span></h1><h3 class=subtitle><span class=date>June 23 - 27, 2025</span>
<span class=bullet-point>• </span><span class=location>Anaheim, California, US</span></h3></div><div class=drawing><img src=/mobisys/2025/images/anaheim.svg role=img alt="MobiSys 2025"></div></div></header><main><div class=container><h1>IoT Day Program</h1><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>08:20 AM - 08:30 AM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><h3 class=timeline-item-title>Opening Remarks</h3><div class=timeline-item-body></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>08:30 AM - 09:30 AM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><div class=timeline-item-body><div class=panel id=keynote-1><div class=panel-header><div class=panel-title-container><div class=panel-title-row><h3>Keynote 1 - How IoT Systems Are Improving Healthcare Delivery in Low-Income Countries</h3><button class=panel-toggle aria-expanded=true aria-controls=keynote-1>
<span class=panel-toggle-icon><i class="bi bi-plus-lg plus-icon"></i>
<i class="bi bi-dash-lg minus-icon"></i></span></button></div><div class=panel-subheader><b>Speaker:</b> Martin Lukac, Co-Founder and CTO of Nexleaf Analytics<br><b>Moderator:</b> Tianxing Li, Assistant Professor, Michigan State University</div></div></div><div class="panel-content clearfix"><div class=panel-inner-content><div style="margin:0 1rem 0 0;float:left"><img src=../images/iot_day/martin_lukac.jpg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Martin Lukac</div></div></div><div style="margin:0 1rem 0 0;float:left"><img src=../images/profiles/tianxin_li.png alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Tianxing Li</div></div></div><strong>Abstract:</strong> This presentation explores the journey from academic sensor network research to real-world IoT applications in Low and Middle-Income Countries (LMICs). It emphasizes the importance of understanding local context and user needs, showcasing how data-driven approaches can solve critical challenges in health, infrastructure, and beyond. We'll discuss key lessons learned, including the realization that technology alone is not the solution and the essential role of user-centered design and adaptation.<p><strong>Bio:</strong> Dr. Martin L. Lukac, Ph.D. is Co-Founder and CTO of Nexleaf Analytics. Nexleaf is a social impact technology company with the mission to partner with countries to ensure they have the data they need to build lasting solutions that improve the health of people. In his role as CTO, Martin oversees the innovation pipeline and the continuous improvement of technologies saving lives in low- and middle-income countries (LMICs) at scale. Nexleaf technology moves data from more than 28,000 health facilities around the world and has been deployed in over 30 countries.</p><p>Martin received his Ph.D. and M.S. from UCLA in Computer Science and his B.S. in Mathematics and Computer Science from Haverford College. Martin and Nithya Ramanathan started Nexleaf in 2009 in Nithya’s garage. Nexleaf’s co-founders saw the potential for wireless sensor data to address big global challenges. As the smartphone revolution changed the landscape for connectivity, Martin prototyped hardware that provided a crucial link to lifesaving equipment deployed in off-grid parts of the world. Nexleaf’s small team pioneered usage-based financing for clean cookstoves and innovated wireless monitoring for vaccine fridges in remote health clinics. Nexleaf has been honored as a Fast Forward Growth Accelerator company, a Gavi INFUSE Pacesetter, and a Tech Award laureate.</p></div></div></div></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>09:45 AM - 10:45 AM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><div class=timeline-item-body><div class=panel id=keynote-2><div class=panel-header><div class=panel-title-container><div class=panel-title-row><h3>Keynote 2 - From Sensors to Deployed Health Programs</h3><button class=panel-toggle aria-expanded=true aria-controls=keynote-2>
<span class=panel-toggle-icon><i class="bi bi-plus-lg plus-icon"></i>
<i class="bi bi-dash-lg minus-icon"></i></span></button></div><div class=panel-subheader><b>Speaker:</b> Ashutosh Sabharwal, Ernest D. Butcher Professor of Engineering, Rice University<br><b>Moderator:</b> VP Nguyen, Assistant Professor, University of Massachusetts Amherst</div></div></div><div class="panel-content clearfix"><div class=panel-inner-content><div style="margin:0 1rem 0 0;float:left"><img src=../images/iot_day/ashutosh_subrarwal.jpg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Ashutosh Sabharwal</div></div></div><div style="margin:0 1rem 0 0;float:left"><img src=../images/profiles/phuc_nguyen.jpeg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>VP Nguyen</div></div></div><strong>Abstract:</strong> We share our ongoing journey from innovation to adoption in deployed clinical workflows. We present case studies in pulmonology, diabetes care, and mental health. We highlight how different methodologies - reductive thinking, systems thinking, and partnerships - play a role in different stages of the project.<p><strong>Bio:</strong> Ashu works in two independent areas - wireless networks and digital health. His ongoing work in wireless focuses on joint wireless communications & imaging and large-scale experimental platforms. He was a co-inventor of full-duplex wireless, which has been adopted in communications standards. He also led the WARP and RENEW projects, which were instrumental in establishing open-source wireless research platforms. He leads the Rice Digital Health Initiative (<a href=https://dhi.rice.edu target=_blank>dhi.rice.edu</a>) and is the co-director of the Methodist-Rice Digital Health Institute. His digital health research focus is the development of devices and data science to quantify behavior-biology pathways across many diseases. He co-founded Cognita Labs, which has developed multiple FDA-cleared medical devices. He was awarded the 2017 IEEE Jack Neubauer Memorial Award, the 2018 IEEE Advances in Communications Award, the 2019 & 2021 ACM Test-of-time Awards, the 2019 ACM MobiCom Community Contribution Award, and the 2023 ICC Best Paper Award. He is a Fellow of IEEE, ACM, and the National Academy of Inventors.</p></div></div></div></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>11:00 AM - 12:00 PM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><div class=timeline-item-body><div class=panel id=keynote-3><div class=panel-header><div class=panel-title-container><div class=panel-title-row><h3>Keynote 3 - Building Human-Centered Interfaces for Wearable AI</h3><button class=panel-toggle aria-expanded=true aria-controls=keynote-3>
<span class=panel-toggle-icon><i class="bi bi-plus-lg plus-icon"></i>
<i class="bi bi-dash-lg minus-icon"></i></span></button></div><div class=panel-subheader><b>Speaker:</b> Hanchuan Li, Research Scientist, Meta Reality Labs Research<br><b>Moderator:</b> Wei Gao, Associate Professor, University of Pittsburgh</div></div></div><div class="panel-content clearfix"><div class=panel-inner-content><div style="margin:0 1rem 0 0;float:left"><img src=../images/iot_day/hanchuan_li.jpeg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Hanchuan Li</div></div></div><div style="margin:0 1rem 0 0;float:left"><img src=../images/profiles/wei_gao.jpg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Wei Gao</div></div></div><strong>Abstract:</strong> The convergence of Artificial Intelligence and all-day wearables is set to unlock the next era of personal computing: a persistent, context-aware assistant that enhances our daily activities. Realizing this vision with all-day wearables demands breakthroughs across a spectrum of technologies. One of the most pivotal challenges lies in defining human interactions with this ever-present technology. To create an experience that is truly seamless, we need to develop rich, intuitive modes of interactions. This talk will highlight the cutting-edge research from Meta Reality Labs Research aimed at solving this problem. We will delve into our work on novel sensing and interaction techniques and discuss how these innovations, leveraged by sophisticated contextual AI, are forging truly frictionless and expressive human-centered interfaces.<p><strong>Bio:</strong> Hanchuan Li is a Research Scientist at Meta Reality Labs Research, where he is inventing the next generation of human-computer interaction for context-aware AI and augmented reality. He leads cross-disciplinary projects that prototype and incubate novel wearable systems—turning rich, real-time understanding of the world into seamless user experiences. Before joining Meta, Hanchuan was a Principal Researcher on the Microsoft HoloLens team, shaping core interaction, CV and XR streaming technologies that shipped in multiple platforms. His interests span across AR/VR, machine learning, interaction techniques, computer vision, real-time graphics, ubiquitous computing, and low-latency streaming, with a consistent focus on bridging state-of-the-art research with practical engineering solutions. His work in the past decade has resulted in high-impact products, platforms, and highly cited research publications. He thrives on building the impossible alongside inspiring collaborators, and on imagining how technology can feel less like a tool and more like an extension of ourselves.</p></div></div></div></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>12:00 PM - 02:00 PM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> FiRE+iCE Interactive Grill & Bar</div><div class=timeline-item-content><h3 class=timeline-item-title>Lunch</h3><div class=timeline-item-body></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>02:00 PM - 03:00 PM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><div class=timeline-item-body><div class=panel id=keynote-4><div class=panel-header><div class=panel-title-container><div class=panel-title-row><h3>Keynote 4 - Time-Sensitive LLM Serving for Robotic Systems</h3><button class=panel-toggle aria-expanded=true aria-controls=keynote-4>
<span class=panel-toggle-icon><i class="bi bi-plus-lg plus-icon"></i>
<i class="bi bi-dash-lg minus-icon"></i></span></button></div><div class=panel-subheader><b>Speaker:</b> Lin Zhong, Joseph C. Tsai Professor, Yale University<br><b>Moderator:</b> Jeremy Gummeson, Assistant Professor, University of Massachusetts Amherst</div></div></div><div class="panel-content clearfix"><div class=panel-inner-content><div style="margin:0 1rem 0 0;float:left"><img src=../images/iot_day/lin_zhong.jpg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Lin Zhong</div></div></div><div style="margin:0 1rem 0 0;float:left"><img src=../images/iot_day/jeremy_gummeson.jpg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Jeremy Gummeson</div></div></div><strong>Abstract:</strong> Large language models (LLMs) have shown remarkable capabilities in reasoning and world knowledge, making them promising components for intelligent robotic systems. However, current LLM serving architectures are poorly suited for time-sensitive tasks such as real-time control and decision-making in robotics. Inference is often slow—partly because LLMs are trained to reason with human language and operate within a rigid autoregressive decoding loop. More critically, existing systems lack temporal awareness, processing prompts in a first-come, first-served fashion without regard to deadlines or task priority. This talk presents our recent work on rethinking LLM serving to meet the stringent latency and responsiveness demands of robotic applications. It will highlight key design principles and outline a multidisciplinary research agenda.<p><strong>Bio:</strong> Lin Zhong is Joseph C. Tsai Professor of Computer Science with Yale University. He received his B.S and M.S. from Tsinghua University and Ph.D. from Princeton University. From 2005 to 2019, he was with Rice University. At Yale, he leads the Efficient Computing Lab to make computing, communication, and interfacing more efficient and effective. He and his students received the best paper awards from ACM MobileHCI, IEEE PerCom, ACM MobiSys (3), ACM ASPLOS, IEEE QCE and NDSS. He is a recipient of the NSF CAREER Award, the Duncan Award from Rice University, the RockStar Award (2014) and Test of Time Award (2022) from ACM SIGMOBILE. He is a Fellow of IEEE and ACM. More information about his research can be found at <a href=https://www.yecl.org/ target=_blank>https://www.yecl.org/</a>.</p></div></div></div></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>03:15 PM - 04:15 PM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><div class=timeline-item-body><div class=panel id=keynote-5><div class=panel-header><div class=panel-title-container><div class=panel-title-row><h3>Keynote 5 - Living with C-3PO and R2-D2: Understanding Privacy for Physical AI</h3><button class=panel-toggle aria-expanded=true aria-controls=keynote-5>
<span class=panel-toggle-icon><i class="bi bi-plus-lg plus-icon"></i>
<i class="bi bi-dash-lg minus-icon"></i></span></button></div><div class=panel-subheader><b>Speaker:</b> Landon Cox, Senior Principal Researcher, Microsoft Research<br><b>Moderator:</b> Akshay Gadre, Assistant Professor, University of Washington</div></div></div><div class="panel-content clearfix"><div class=panel-inner-content><div style="margin:0 1rem 0 0;float:left"><img src=../images/iot_day/landon_cox.jpg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Landon Cox</div></div></div><div style="margin:0 1rem 0 0;float:left"><img src=../images/iot_day/akshay_gadre.jpg alt="Profile Picture" style="display:block;width:180px;height:180px;object-fit:cover;border-radius:4px;box-shadow:0 2px 8px rgba(0,0,0,.1);border:2px solid #fff"><div class=image-info><div class=image-ref>Akshay Gadre</div></div></div><strong>Abstract:</strong> Artificial intelligence (AI) advancements that interact with the physical world through robots, wearables, and cameras are coming. Consider a domestic service where a team of simple robots helps tidy up. An individual robot may be capable of simple tasks on its own, like picking up trash; other tasks, such as unpacking and putting away groceries, may require multiple robots to coordinate. These robots will require physical AI to translate visual and audio observations into semantics and capture the location and motion of objects. The robots will process data from microphones, LIDAR, and cameras to safely navigate and manipulate objects. The robots may also use information from cameras and microphones in the home. This talk will consider how these systems might influence our sense of privacy (and vice versa), and what regulatory and technical guardrails (if any) might emerge as sensing and AI become seamlessly integrated with our physical environments.<p><strong>Bio:</strong> Landon Cox is a Senior Principal Researcher at Microsoft Research, Redmond. He most recently worked on Azure Programmable Connectivity (APC) and helped deploy Exposure Notification in the state of Washington. Landon was honored as an ACM Distinguished Member for his work on privacy in mobile computing and operating systems and received a SIGOPS Hall of Fame Award for his OSDI 2010 paper. Prior to joining Microsoft, he was a tenured professor at Duke University.</p></div></div></div></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>04:30 PM - 05:20 PM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><h3 class=timeline-item-title>Panel discussion</h3><div class=timeline-item-body></div></div></div></div><div class=timeline-wrapper><div class=timeline-item><div class=timeline-item-time>05:20 PM</div><div class=timeline-item-location><i class="bi bi-geo-fill"></i> Pacific Ballroom C</div><div class=timeline-item-content><h3 class=timeline-item-title>Closing remarks</h3><div class=timeline-item-body></div></div></div></div></div></main><footer><div class=container><div class=footer-sponsor><div class=sponsor><h2>Sponsors</h2><div class=sponsor-item><a href=https://www.acm.org target=_blank><img src=/mobisys/2025/images/sponsors/acm.svg>
</a><a href=https://www.sigmobile.org/grav/ target=_blank><img src=/mobisys/2025/images/sponsors/sigmobile.svg></a></div></div><div class=sponsor><h3>Gold Sponsors</h3><div class=sponsor-item><a href=https://www.futurewei.com/ target=_blank><img class=gold-sponsor role=img src=/mobisys/2025/images/sponsors/futurewei.svg></a></div></div><div class=sponsor><h3>Silver Sponsors</h3><div class=sponsor-item><a href=https://www.google.com/ target=_blank><img class=silver-sponsor src=/mobisys/2025/images/sponsors/google.png></a></div><div class=sponsor-item style=margin-top:1.5em><a href=https://home.dartmouth.edu/ target=_blank><img style=max-width:20em class=silver-sponsor src=/mobisys/2025/images/sponsors/dartmouth.png></a></div></div></div><div class=footer-content><div class=copyright><span>&copy; 2025 ACM | Header &copy;&nbsp;
<a href=https://stock.adobe.com target=_blank>Simple Line</a></span></div><div class="flex flex-column justify-around items-center gap-4"><a href=https://github.com/mobisys2025/website target=_blank><i class="bi bi-github"></i></a>
<a href=mailto:mingyi.chen@uci.edu,zhibowang@zju.edu.cn,zr_12f@zju.edu.cn><i class="bi bi-envelope-paper-fill"></i></a></div></div></div></footer><script src=/mobisys/2025/js/nav.min.d01ed11bf91764a4f3da5f6b3ca7a9586dd1d97ecf8b2740c36dded217e84416.js integrity="sha256-0B7RG/kXZKTz2l9rPKepWG3R2X7PiydAw23e0hfoRBY=" crossorigin=anonymous></script><script src=/mobisys/2025/js/modernizr.min.min.9e67fc0aad7aa44f2b827af89e0bc5855696d36f45f983bad0637c2f4ae9e215.js integrity="sha256-nmf8Cq16pE8rgnr4ngvFhVaW029F+YO60GN8L0rp4hU=" crossorigin=anonymous></script><script src=/mobisys/2025/css/icomoon/liga.js></script></body></html>