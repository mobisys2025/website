---
title: "IoT Day Program"
---

{{< timeline time="08:20 AM - 08:30 AM" title="Opening Remarks" location="Pacific Ballroom C" >}}
{{< /timeline >}}

{{< timeline time="08:30 AM - 09:30 AM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 1" subheader="Speaker: Kamin Whitehouse, Amazon" >}}
{{< profile_pic src="../images/iot_day/kamin_whitehouse.jpeg" >}}
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="09:45 AM - 10:45 AM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 2" subheader="Speaker: Ashutosh Sabharwal, Ernest D. Butcher Professor of Engineering, Rice University" >}}
    {{< profile_pic src="../images/iot_day/ashutosh_subrarwal.jpg" >}}
    <h3>From Sensors to Deployed Health Programs</h3>
    <p><strong>Abstract:</strong> We share our ongoing journey from innovation to adoption in deployed clinical workflows. We present case studies in pulmonology, diabetes care, and mental health. We highlight how different methodologies - reductive thinking, systems thinking, and partnerships - play a role in different stages of the project.</p>
    <p><strong>Bio:</strong> Ashu works in two independent areas - wireless networks and digital health. His ongoing work in wireless focuses on joint wireless communications & imaging and large-scale experimental platforms. He was a co-inventor of full-duplex wireless, which has been adopted in communications standards. He also led the WARP and RENEW projects, which were instrumental in establishing open-source wireless research platforms. He leads the Rice Digital Health Initiative (<a href="https://dhi.rice.edu" target="_blank">dhi.rice.edu</a>) and is the co-director of the Methodist-Rice Digital Health Institute. His digital health research focus is the development of devices and data science to quantify behavior-biology pathways across many diseases. He co-founded Cognita Labs, which has developed multiple FDA-cleared medical devices. He was awarded the 2017 IEEE Jack Neubauer Memorial Award, the 2018 IEEE Advances in Communications Award, the 2019 & 2021 ACM Test-of-time Awards, the 2019 ACM MobiCom Community Contribution Award, and the 2023 ICC Best Paper Award. He is a Fellow of IEEE, ACM, and the National Academy of Inventors.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="11:00 AM - 12:00 PM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 3" subheader="Speaker: Hanchuan Li, Research Scientist, Meta Reality Labs Research" >}}
    {{< profile_pic src="../images/iot_day/hanchuan_li.jpeg" >}}
    <h3>Building Human-Centered Interfaces for Wearable AI</h3>
    <p><strong>Abstract:</strong> The convergence of Artificial Intelligence and all-day wearables is set to unlock the next era of personal computing: a persistent, context-aware assistant that enhances our daily activities. Realizing this vision with all-day wearables demands breakthroughs across a spectrum of technologies. One of the most pivotal challenges lies in defining human interactions with this ever-present technology. To create an experience that is truly seamless, we need to develop rich, intuitive modes of interactions. This talk will highlight the cutting-edge research from Meta Reality Labs Research aimed at solving this problem. We will delve into our work on novel sensing and interaction techniques and discuss how these innovations, leveraged by sophisticated contextual AI, are forging truly frictionless and expressive human-centered interfaces.</p>
    <p><strong>Bio:</strong> Hanchuan Li is a Research Scientist at Meta Reality Labs Research, where he is inventing the next generation of human-computer interaction for context-aware AI and augmented reality. He leads cross-disciplinary projects that prototype and incubate novel wearable systems—turning rich, real-time understanding of the world into seamless user experiences. Before joining Meta, Hanchuan was a Principal Researcher on the Microsoft HoloLens team, shaping core interaction, CV and XR streaming technologies that shipped in multiple platforms. His interests span across AR/VR, machine learning, interaction techniques, computer vision, real-time graphics, ubiquitous computing, and low-latency streaming, with a consistent focus on bridging state-of-the-art research with practical engineering solutions. His work in the past decade has resulted in high-impact products, platforms, and highly cited research publications. He thrives on building the impossible alongside inspiring collaborators, and on imagining how technology can feel less like a tool and more like an extension of ourselves.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="12:00 PM - 02:00 PM" title="Lunch" location="Outside Restaurant" >}}
{{< /timeline >}}

{{< timeline time="02:00 PM - 03:00 PM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 4" subheader="Speaker: Lin Zhong, Joseph C. Tsai Professor, Yale University" >}}
    {{< profile_pic src="../images/iot_day/lin_zhong.jpg" >}}
    <h3>Time-Sensitive LLM Serving for Robotic Systems</h3>
    <p><strong>Abstract:</strong> Large language models (LLMs) have shown remarkable capabilities in reasoning and world knowledge, making them promising components for intelligent robotic systems. However, current LLM serving architectures are poorly suited for time-sensitive tasks such as real-time control and decision-making in robotics. Inference is often slow—partly because LLMs are trained to reason with human language and operate within a rigid autoregressive decoding loop. More critically, existing systems lack temporal awareness, processing prompts in a first-come, first-served fashion without regard to deadlines or task priority. This talk presents our recent work on rethinking LLM serving to meet the stringent latency and responsiveness demands of robotic applications. It will highlight key design principles and outline a multidisciplinary research agenda.</p>
    <p><strong>Bio:</strong> Lin Zhong is Joseph C. Tsai Professor of Computer Science with Yale University. He received his B.S and M.S. from Tsinghua University and Ph.D. from Princeton University. From 2005 to 2019, he was with Rice University. At Yale, he leads the Efficient Computing Lab to make computing, communication, and interfacing more efficient and effective. He and his students received the best paper awards from ACM MobileHCI, IEEE PerCom, ACM MobiSys (3), ACM ASPLOS, IEEE QCE and NDSS. He is a recipient of the NSF CAREER Award, the Duncan Award from Rice University, the RockStar Award (2014) and Test of Time Award (2022) from ACM SIGMOBILE. He is a Fellow of IEEE and ACM. More information about his research can be found at <a href="https://www.yecl.org/" target="_blank">https://www.yecl.org/</a>.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="03:15 PM - 04:15 PM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 5" subheader="Speaker: Landon Cox, Senior Principal Researcher, Microsoft Research" >}}
    {{< profile_pic src="../images/iot_day/landon_cox.jpg" >}}
    <h3>Living with C-3PO and R2-D2: Understanding Privacy for Physical AI</h3>
    <p><strong>Abstract:</strong> Artificial intelligence (AI) advancements that interact with the physical world through robots, wearables, and cameras are coming. Consider a domestic service where a team of simple robots helps tidy up. An individual robot may be capable of simple tasks on its own, like picking up trash; other tasks, such as unpacking and putting away groceries, may require multiple robots to coordinate. These robots will require physical AI to translate visual and audio observations into semantics and capture the location and motion of objects. The robots will process data from microphones, LIDAR, and cameras to safely navigate and manipulate objects. The robots may also use information from cameras and microphones in the home. This talk will consider how these systems might influence our sense of privacy (and vice versa), and what regulatory and technical guardrails (if any) might emerge as sensing and AI become seamlessly integrated with our physical environments.</p>
    <p><strong>Bio:</strong> Landon Cox is a Senior Principal Researcher at Microsoft Research, Redmond. He most recently worked on Azure Programmable Connectivity (APC) and helped deploy Exposure Notification in the state of Washington. Landon was honored as an ACM Distinguished Member for his work on privacy in mobile computing and operating systems and received a SIGOPS Hall of Fame Award for his OSDI 2010 paper. Prior to joining Microsoft, he was a tenured professor at Duke University.</p>
{{< /panel >}}
{{< /timeline >}}

<!-- {{< timeline time="03:15 PM - 03:45 PM" title="Coffee Break" >}}
{{< /timeline >}} -->

{{< timeline time="04:30 PM - 05:20 PM" title="Panel discussion" location="Pacific Ballroom C" >}}
{{< /timeline >}}

{{< timeline time="05:20 PM" title="Closing remarks" location="Pacific Ballroom C" >}}
{{< /timeline >}}
