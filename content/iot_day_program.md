---
title: "IoT Day Program"
---

{{< timeline time="08:20 AM - 08:30 AM" title="Opening Remarks" location="Pacific Ballroom C" >}}
{{< /timeline >}}

{{< timeline time="08:30 AM - 09:30 AM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 1 - How IoT Systems Are Improving Healthcare Delivery in Low-Income Countries" subheader="<b>Speaker:</b> Martin Lukac, Co-Founder and CTO of Nexleaf Analytics<br><b>Moderator:</b> Tianxing Li, Assistant Professor, Michigan State University" id="keynote-1" >}}
    {{< profile_pic src="../images/iot_day/martin_lukac.jpg" title="Martin Lukac" >}}
    {{< profile_pic src="../images/profiles/tianxin_li.png" title="Tianxing Li" >}}
    <strong>Abstract:</strong> This presentation explores the journey from academic sensor network research to real-world IoT applications in Low and Middle-Income Countries (LMICs). It emphasizes the importance of understanding local context and user needs, showcasing how data-driven approaches can solve critical challenges in health, infrastructure, and beyond. We'll discuss key lessons learned, including the realization that technology alone is not the solution and the essential role of user-centered design and adaptation.
    <p><strong>Bio:</strong> Dr. Martin L. Lukac, Ph.D. is Co-Founder and CTO of Nexleaf Analytics. Nexleaf is a social impact technology company with the mission to partner with countries to ensure they have the data they need to build lasting solutions that improve the health of people. In his role as CTO, Martin oversees the innovation pipeline and the continuous improvement of technologies saving lives in low- and middle-income countries (LMICs) at scale. Nexleaf technology moves data from more than 28,000 health facilities around the world and has been deployed in over 30 countries.</p>
    <p>Martin received his Ph.D. and M.S. from UCLA in Computer Science and his B.S. in Mathematics and Computer Science from Haverford College. Martin and Nithya Ramanathan started Nexleaf in 2009 in Nithya’s garage. Nexleaf’s co-founders saw the potential for wireless sensor data to address big global challenges. As the smartphone revolution changed the landscape for connectivity, Martin prototyped hardware that provided a crucial link to lifesaving equipment deployed in off-grid parts of the world. Nexleaf’s small team pioneered usage-based financing for clean cookstoves and innovated wireless monitoring for vaccine fridges in remote health clinics. Nexleaf has been honored as a Fast Forward Growth Accelerator company, a Gavi INFUSE Pacesetter, and a Tech Award laureate.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="09:45 AM - 10:45 AM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 2 - From Sensors to Deployed Health Programs" subheader="<b>Speaker:</b> Ashutosh Sabharwal, Ernest D. Butcher Professor of Engineering, Rice University<br><b>Moderator:</b> VP Nguyen, Assistant Professor, University of Massachusetts Amherst" id="keynote-2" >}}
    {{< profile_pic src="../images/iot_day/ashutosh_subrarwal.jpg" title="Ashutosh Sabharwal" >}}
    {{< profile_pic src="../images/profiles/phuc_nguyen.jpeg" title="VP Nguyen" >}}
    <strong>Abstract:</strong> We share our ongoing journey from innovation to adoption in deployed clinical workflows. We present case studies in pulmonology, diabetes care, and mental health. We highlight how different methodologies - reductive thinking, systems thinking, and partnerships - play a role in different stages of the project.
    <p><strong>Bio:</strong> Ashu works in two independent areas - wireless networks and digital health. His ongoing work in wireless focuses on joint wireless communications & imaging and large-scale experimental platforms. He was a co-inventor of full-duplex wireless, which has been adopted in communications standards. He also led the WARP and RENEW projects, which were instrumental in establishing open-source wireless research platforms. He leads the Rice Digital Health Initiative (<a href="https://dhi.rice.edu" target="_blank">dhi.rice.edu</a>) and is the co-director of the Methodist-Rice Digital Health Institute. His digital health research focus is the development of devices and data science to quantify behavior-biology pathways across many diseases. He co-founded Cognita Labs, which has developed multiple FDA-cleared medical devices. He was awarded the 2017 IEEE Jack Neubauer Memorial Award, the 2018 IEEE Advances in Communications Award, the 2019 & 2021 ACM Test-of-time Awards, the 2019 ACM MobiCom Community Contribution Award, and the 2023 ICC Best Paper Award. He is a Fellow of IEEE, ACM, and the National Academy of Inventors.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="11:00 AM - 12:00 PM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 3 - Building Human-Centered Interfaces for Wearable AI" subheader="<b>Speaker:</b> Hanchuan Li, Research Scientist, Meta Reality Labs Research<br><b>Moderator:</b> Wei Gao, Associate Professor, University of Pittsburgh" id="keynote-3" >}}
    {{< profile_pic src="../images/iot_day/hanchuan_li.jpeg" title="Hanchuan Li" >}}
    {{< profile_pic src="../images/profiles/wei_gao.jpg" title="Wei Gao" >}}
    <strong>Abstract:</strong> The convergence of Artificial Intelligence and all-day wearables is set to unlock the next era of personal computing: a persistent, context-aware assistant that enhances our daily activities. Realizing this vision with all-day wearables demands breakthroughs across a spectrum of technologies. One of the most pivotal challenges lies in defining human interactions with this ever-present technology. To create an experience that is truly seamless, we need to develop rich, intuitive modes of interactions. This talk will highlight the cutting-edge research from Meta Reality Labs Research aimed at solving this problem. We will delve into our work on novel sensing and interaction techniques and discuss how these innovations, leveraged by sophisticated contextual AI, are forging truly frictionless and expressive human-centered interfaces.
    <p><strong>Bio:</strong> Hanchuan Li is a Research Scientist at Meta Reality Labs Research, where he is inventing the next generation of human-computer interaction for context-aware AI and augmented reality. He leads cross-disciplinary projects that prototype and incubate novel wearable systems—turning rich, real-time understanding of the world into seamless user experiences. Before joining Meta, Hanchuan was a Principal Researcher on the Microsoft HoloLens team, shaping core interaction, CV and XR streaming technologies that shipped in multiple platforms. His interests span across AR/VR, machine learning, interaction techniques, computer vision, real-time graphics, ubiquitous computing, and low-latency streaming, with a consistent focus on bridging state-of-the-art research with practical engineering solutions. His work in the past decade has resulted in high-impact products, platforms, and highly cited research publications. He thrives on building the impossible alongside inspiring collaborators, and on imagining how technology can feel less like a tool and more like an extension of ourselves.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="12:00 PM - 02:00 PM" title="Lunch" location="FiRE+iCE Interactive Grill & Bar" >}}
{{< /timeline >}}

{{< timeline time="02:00 PM - 03:00 PM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 4 - Time-Sensitive LLM Serving for Robotic Systems" subheader="<b>Speaker:</b> Lin Zhong, Joseph C. Tsai Professor, Yale University<br><b>Moderator:</b> Jeremy Gummeson, Assistant Professor, University of Massachusetts Amherst" id="keynote-4" >}}
    {{< profile_pic src="../images/iot_day/lin_zhong.jpg" title="Lin Zhong" >}}
    {{< profile_pic src="../images/iot_day/jeremy_gummeson.jpg" title="Jeremy Gummeson" >}}
    <strong>Abstract:</strong> Large language models (LLMs) have shown remarkable capabilities in reasoning and world knowledge, making them promising components for intelligent robotic systems. However, current LLM serving architectures are poorly suited for time-sensitive tasks such as real-time control and decision-making in robotics. Inference is often slow—partly because LLMs are trained to reason with human language and operate within a rigid autoregressive decoding loop. More critically, existing systems lack temporal awareness, processing prompts in a first-come, first-served fashion without regard to deadlines or task priority. This talk presents our recent work on rethinking LLM serving to meet the stringent latency and responsiveness demands of robotic applications. It will highlight key design principles and outline a multidisciplinary research agenda.
    <p><strong>Bio:</strong> Lin Zhong is Joseph C. Tsai Professor of Computer Science with Yale University. He received his B.S and M.S. from Tsinghua University and Ph.D. from Princeton University. From 2005 to 2019, he was with Rice University. At Yale, he leads the Efficient Computing Lab to make computing, communication, and interfacing more efficient and effective. He and his students received the best paper awards from ACM MobileHCI, IEEE PerCom, ACM MobiSys (3), ACM ASPLOS, IEEE QCE and NDSS. He is a recipient of the NSF CAREER Award, the Duncan Award from Rice University, the RockStar Award (2014) and Test of Time Award (2022) from ACM SIGMOBILE. He is a Fellow of IEEE and ACM. More information about his research can be found at <a href="https://www.yecl.org/" target="_blank">https://www.yecl.org/</a>.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="03:15 PM - 04:15 PM" location="Pacific Ballroom C" >}}
{{< panel header="Keynote 5 - Living with C-3PO and R2-D2: Understanding Privacy for Physical AI" subheader="<b>Speaker:</b> Landon Cox, Senior Principal Researcher, Microsoft Research<br><b>Moderator:</b> Akshay Gadre, Assistant Professor, University of Washington" id="keynote-5" >}}
    {{< profile_pic src="../images/iot_day/landon_cox.jpg" title="Landon Cox" >}}
    {{< profile_pic src="../images/iot_day/akshay_gadre.jpg" title="Akshay Gadre" >}}
    <strong>Abstract:</strong> Artificial intelligence (AI) advancements that interact with the physical world through robots, wearables, and cameras are coming. Consider a domestic service where a team of simple robots helps tidy up. An individual robot may be capable of simple tasks on its own, like picking up trash; other tasks, such as unpacking and putting away groceries, may require multiple robots to coordinate. These robots will require physical AI to translate visual and audio observations into semantics and capture the location and motion of objects. The robots will process data from microphones, LIDAR, and cameras to safely navigate and manipulate objects. The robots may also use information from cameras and microphones in the home. This talk will consider how these systems might influence our sense of privacy (and vice versa), and what regulatory and technical guardrails (if any) might emerge as sensing and AI become seamlessly integrated with our physical environments.
    <p><strong>Bio:</strong> Landon Cox is a Senior Principal Researcher at Microsoft Research, Redmond. He most recently worked on Azure Programmable Connectivity (APC) and helped deploy Exposure Notification in the state of Washington. Landon was honored as an ACM Distinguished Member for his work on privacy in mobile computing and operating systems and received a SIGOPS Hall of Fame Award for his OSDI 2010 paper. Prior to joining Microsoft, he was a tenured professor at Duke University.</p>
{{< /panel >}}
{{< /timeline >}}

{{< timeline time="04:30 PM - 05:20 PM" title="Panel discussion" location="Pacific Ballroom C" >}}
{{< /timeline >}}

{{< timeline time="05:20 PM" title="Closing remarks" location="Pacific Ballroom C" >}}
{{< /timeline >}}
